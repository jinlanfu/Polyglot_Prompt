export model_dir='./models'
export taskname="pawsx"
export model_name="mt5base_polyprompt_crossLanguage"
export output_dir='./models'
export model_path=${model_dir}/${model_name}/'checkpoint-8000'
export datadir='./datas/datas_CL_pt'
export prompt_dir='./datas/templates/CL'

export num_train_epochs=18
export save_steps=4000
export do_train=False
export do_eval=True
export do_test=True
export PER_DEVICE_TRAIN_BATCH_SIZE=10
export PER_DEVICE_EVAL_BATCH_SIZE=2
export gradient_accumulation_steps=6
export eval_batch_size=100

CUDA_VISIBLE_DEVICES=1  python ./train_mt5.py \
    --output_dir=$output_dir \
    --taskname=${taskname} \
    --model_name_or_path=$model_path \
    --model_name=$model_name \
    --model_dir=$model_dir \
    --test_file_dir=$test_file_dir \
     --per_device_train_batch_size=$PER_DEVICE_TRAIN_BATCH_SIZE \
     --per_device_eval_batch_size=$PER_DEVICE_EVAL_BATCH_SIZE \
     --source_max_len=512 \
     --target_max_len=64 \
     --eval_batch_size=$eval_batch_size \
     --gradient_accumulation_steps=${gradient_accumulation_steps} \
    --learning_rate=1e-4 \
    --num_train_epochs=$num_train_epochs \
    --save_steps=$save_steps \
    --do_train=$do_train \
    --do_eval=$do_eval \
    --prompt_dir=$prompt_dir \
    --data_dir=$datadir \

